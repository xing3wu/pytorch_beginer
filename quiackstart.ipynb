{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.784621  [   64/60000]\n",
      "loss: 0.870048  [ 6464/60000]\n",
      "loss: 0.638906  [12864/60000]\n",
      "loss: 0.843455  [19264/60000]\n",
      "loss: 0.746227  [25664/60000]\n",
      "loss: 0.730749  [32064/60000]\n",
      "loss: 0.814534  [38464/60000]\n",
      "loss: 0.794492  [44864/60000]\n",
      "loss: 0.797450  [51264/60000]\n",
      "loss: 0.752033  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.760257 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.747674  [   64/60000]\n",
      "loss: 0.841099  [ 6464/60000]\n",
      "loss: 0.607573  [12864/60000]\n",
      "loss: 0.819809  [19264/60000]\n",
      "loss: 0.724510  [25664/60000]\n",
      "loss: 0.705564  [32064/60000]\n",
      "loss: 0.790448  [38464/60000]\n",
      "loss: 0.777355  [44864/60000]\n",
      "loss: 0.775011  [51264/60000]\n",
      "loss: 0.730829  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.738388 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.715250  [   64/60000]\n",
      "loss: 0.814919  [ 6464/60000]\n",
      "loss: 0.580843  [12864/60000]\n",
      "loss: 0.799778  [19264/60000]\n",
      "loss: 0.705784  [25664/60000]\n",
      "loss: 0.684808  [32064/60000]\n",
      "loss: 0.768308  [38464/60000]\n",
      "loss: 0.762192  [44864/60000]\n",
      "loss: 0.755482  [51264/60000]\n",
      "loss: 0.712050  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.718977 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.686333  [   64/60000]\n",
      "loss: 0.790803  [ 6464/60000]\n",
      "loss: 0.557639  [12864/60000]\n",
      "loss: 0.782050  [19264/60000]\n",
      "loss: 0.688982  [25664/60000]\n",
      "loss: 0.667262  [32064/60000]\n",
      "loss: 0.747735  [38464/60000]\n",
      "loss: 0.748409  [44864/60000]\n",
      "loss: 0.738160  [51264/60000]\n",
      "loss: 0.694972  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.701386 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.660374  [   64/60000]\n",
      "loss: 0.768497  [ 6464/60000]\n",
      "loss: 0.537109  [12864/60000]\n",
      "loss: 0.766115  [19264/60000]\n",
      "loss: 0.673925  [25664/60000]\n",
      "loss: 0.652097  [32064/60000]\n",
      "loss: 0.728418  [38464/60000]\n",
      "loss: 0.735799  [44864/60000]\n",
      "loss: 0.722547  [51264/60000]\n",
      "loss: 0.679234  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.685253 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.636934  [   64/60000]\n",
      "loss: 0.747630  [ 6464/60000]\n",
      "loss: 0.518724  [12864/60000]\n",
      "loss: 0.751590  [19264/60000]\n",
      "loss: 0.660477  [25664/60000]\n",
      "loss: 0.638845  [32064/60000]\n",
      "loss: 0.710253  [38464/60000]\n",
      "loss: 0.724165  [44864/60000]\n",
      "loss: 0.708499  [51264/60000]\n",
      "loss: 0.664534  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.670345 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.615693  [   64/60000]\n",
      "loss: 0.728076  [ 6464/60000]\n",
      "loss: 0.502177  [12864/60000]\n",
      "loss: 0.738120  [19264/60000]\n",
      "loss: 0.648424  [25664/60000]\n",
      "loss: 0.627085  [32064/60000]\n",
      "loss: 0.693207  [38464/60000]\n",
      "loss: 0.713565  [44864/60000]\n",
      "loss: 0.695960  [51264/60000]\n",
      "loss: 0.650772  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.656564 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.596423  [   64/60000]\n",
      "loss: 0.709943  [ 6464/60000]\n",
      "loss: 0.487247  [12864/60000]\n",
      "loss: 0.725474  [19264/60000]\n",
      "loss: 0.637684  [25664/60000]\n",
      "loss: 0.616629  [32064/60000]\n",
      "loss: 0.677239  [38464/60000]\n",
      "loss: 0.704062  [44864/60000]\n",
      "loss: 0.684916  [51264/60000]\n",
      "loss: 0.637926  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.643820 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.578918  [   64/60000]\n",
      "loss: 0.693207  [ 6464/60000]\n",
      "loss: 0.473710  [12864/60000]\n",
      "loss: 0.713584  [19264/60000]\n",
      "loss: 0.628178  [25664/60000]\n",
      "loss: 0.607407  [32064/60000]\n",
      "loss: 0.662225  [38464/60000]\n",
      "loss: 0.695652  [44864/60000]\n",
      "loss: 0.675257  [51264/60000]\n",
      "loss: 0.625881  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.632044 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.562998  [   64/60000]\n",
      "loss: 0.677701  [ 6464/60000]\n",
      "loss: 0.461390  [12864/60000]\n",
      "loss: 0.702504  [19264/60000]\n",
      "loss: 0.619548  [25664/60000]\n",
      "loss: 0.599180  [32064/60000]\n",
      "loss: 0.648161  [38464/60000]\n",
      "loss: 0.688351  [44864/60000]\n",
      "loss: 0.666866  [51264/60000]\n",
      "loss: 0.614551  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.621165 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.548378  [   64/60000]\n",
      "loss: 0.663274  [ 6464/60000]\n",
      "loss: 0.450118  [12864/60000]\n",
      "loss: 0.692035  [19264/60000]\n",
      "loss: 0.611766  [25664/60000]\n",
      "loss: 0.591744  [32064/60000]\n",
      "loss: 0.635081  [38464/60000]\n",
      "loss: 0.682116  [44864/60000]\n",
      "loss: 0.659745  [51264/60000]\n",
      "loss: 0.603861  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.611100 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.534985  [   64/60000]\n",
      "loss: 0.649912  [ 6464/60000]\n",
      "loss: 0.439813  [12864/60000]\n",
      "loss: 0.682208  [19264/60000]\n",
      "loss: 0.604619  [25664/60000]\n",
      "loss: 0.585055  [32064/60000]\n",
      "loss: 0.622859  [38464/60000]\n",
      "loss: 0.676846  [44864/60000]\n",
      "loss: 0.653660  [51264/60000]\n",
      "loss: 0.593781  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.601794 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.522523  [   64/60000]\n",
      "loss: 0.637528  [ 6464/60000]\n",
      "loss: 0.430342  [12864/60000]\n",
      "loss: 0.672923  [19264/60000]\n",
      "loss: 0.597916  [25664/60000]\n",
      "loss: 0.579043  [32064/60000]\n",
      "loss: 0.611531  [38464/60000]\n",
      "loss: 0.672532  [44864/60000]\n",
      "loss: 0.648516  [51264/60000]\n",
      "loss: 0.584164  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.593198 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.510969  [   64/60000]\n",
      "loss: 0.625992  [ 6464/60000]\n",
      "loss: 0.421595  [12864/60000]\n",
      "loss: 0.664199  [19264/60000]\n",
      "loss: 0.591540  [25664/60000]\n",
      "loss: 0.573518  [32064/60000]\n",
      "loss: 0.601097  [38464/60000]\n",
      "loss: 0.669136  [44864/60000]\n",
      "loss: 0.644098  [51264/60000]\n",
      "loss: 0.574903  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.585255 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.500220  [   64/60000]\n",
      "loss: 0.615318  [ 6464/60000]\n",
      "loss: 0.413511  [12864/60000]\n",
      "loss: 0.655949  [19264/60000]\n",
      "loss: 0.585417  [25664/60000]\n",
      "loss: 0.568357  [32064/60000]\n",
      "loss: 0.591403  [38464/60000]\n",
      "loss: 0.666532  [44864/60000]\n",
      "loss: 0.640348  [51264/60000]\n",
      "loss: 0.565843  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.577902 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.490142  [   64/60000]\n",
      "loss: 0.605432  [ 6464/60000]\n",
      "loss: 0.406022  [12864/60000]\n",
      "loss: 0.648079  [19264/60000]\n",
      "loss: 0.579574  [25664/60000]\n",
      "loss: 0.563495  [32064/60000]\n",
      "loss: 0.582380  [38464/60000]\n",
      "loss: 0.664619  [44864/60000]\n",
      "loss: 0.637126  [51264/60000]\n",
      "loss: 0.557150  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.571082 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.480696  [   64/60000]\n",
      "loss: 0.596248  [ 6464/60000]\n",
      "loss: 0.399062  [12864/60000]\n",
      "loss: 0.640596  [19264/60000]\n",
      "loss: 0.573892  [25664/60000]\n",
      "loss: 0.558815  [32064/60000]\n",
      "loss: 0.573967  [38464/60000]\n",
      "loss: 0.663271  [44864/60000]\n",
      "loss: 0.634365  [51264/60000]\n",
      "loss: 0.548757  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.564748 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.471807  [   64/60000]\n",
      "loss: 0.587683  [ 6464/60000]\n",
      "loss: 0.392531  [12864/60000]\n",
      "loss: 0.633447  [19264/60000]\n",
      "loss: 0.568299  [25664/60000]\n",
      "loss: 0.554275  [32064/60000]\n",
      "loss: 0.566203  [38464/60000]\n",
      "loss: 0.662414  [44864/60000]\n",
      "loss: 0.631924  [51264/60000]\n",
      "loss: 0.540649  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.558863 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.463444  [   64/60000]\n",
      "loss: 0.579684  [ 6464/60000]\n",
      "loss: 0.386431  [12864/60000]\n",
      "loss: 0.626562  [19264/60000]\n",
      "loss: 0.562787  [25664/60000]\n",
      "loss: 0.549856  [32064/60000]\n",
      "loss: 0.559012  [38464/60000]\n",
      "loss: 0.661984  [44864/60000]\n",
      "loss: 0.629827  [51264/60000]\n",
      "loss: 0.532778  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.553383 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.455534  [   64/60000]\n",
      "loss: 0.572210  [ 6464/60000]\n",
      "loss: 0.380699  [12864/60000]\n",
      "loss: 0.619945  [19264/60000]\n",
      "loss: 0.557335  [25664/60000]\n",
      "loss: 0.545519  [32064/60000]\n",
      "loss: 0.552385  [38464/60000]\n",
      "loss: 0.661911  [44864/60000]\n",
      "loss: 0.627978  [51264/60000]\n",
      "loss: 0.525147  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.548274 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.448021  [   64/60000]\n",
      "loss: 0.565271  [ 6464/60000]\n",
      "loss: 0.375345  [12864/60000]\n",
      "loss: 0.613571  [19264/60000]\n",
      "loss: 0.551972  [25664/60000]\n",
      "loss: 0.541257  [32064/60000]\n",
      "loss: 0.546252  [38464/60000]\n",
      "loss: 0.662086  [44864/60000]\n",
      "loss: 0.626253  [51264/60000]\n",
      "loss: 0.517793  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.543508 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.440901  [   64/60000]\n",
      "loss: 0.558809  [ 6464/60000]\n",
      "loss: 0.370306  [12864/60000]\n",
      "loss: 0.607494  [19264/60000]\n",
      "loss: 0.546639  [25664/60000]\n",
      "loss: 0.537055  [32064/60000]\n",
      "loss: 0.540557  [38464/60000]\n",
      "loss: 0.662464  [44864/60000]\n",
      "loss: 0.624626  [51264/60000]\n",
      "loss: 0.510682  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.539059 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.434125  [   64/60000]\n",
      "loss: 0.552796  [ 6464/60000]\n",
      "loss: 0.365537  [12864/60000]\n",
      "loss: 0.601699  [19264/60000]\n",
      "loss: 0.541385  [25664/60000]\n",
      "loss: 0.532930  [32064/60000]\n",
      "loss: 0.535302  [38464/60000]\n",
      "loss: 0.662929  [44864/60000]\n",
      "loss: 0.623092  [51264/60000]\n",
      "loss: 0.503749  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.534895 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.427683  [   64/60000]\n",
      "loss: 0.547271  [ 6464/60000]\n",
      "loss: 0.361056  [12864/60000]\n",
      "loss: 0.596185  [19264/60000]\n",
      "loss: 0.536208  [25664/60000]\n",
      "loss: 0.528796  [32064/60000]\n",
      "loss: 0.530416  [38464/60000]\n",
      "loss: 0.663448  [44864/60000]\n",
      "loss: 0.621584  [51264/60000]\n",
      "loss: 0.497087  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.530985 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.421527  [   64/60000]\n",
      "loss: 0.542140  [ 6464/60000]\n",
      "loss: 0.356827  [12864/60000]\n",
      "loss: 0.590903  [19264/60000]\n",
      "loss: 0.531155  [25664/60000]\n",
      "loss: 0.524722  [32064/60000]\n",
      "loss: 0.525921  [38464/60000]\n",
      "loss: 0.664006  [44864/60000]\n",
      "loss: 0.620148  [51264/60000]\n",
      "loss: 0.490696  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.527309 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.415635  [   64/60000]\n",
      "loss: 0.537369  [ 6464/60000]\n",
      "loss: 0.352855  [12864/60000]\n",
      "loss: 0.585828  [19264/60000]\n",
      "loss: 0.526213  [25664/60000]\n",
      "loss: 0.520717  [32064/60000]\n",
      "loss: 0.521719  [38464/60000]\n",
      "loss: 0.664466  [44864/60000]\n",
      "loss: 0.618735  [51264/60000]\n",
      "loss: 0.484599  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.523850 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.410077  [   64/60000]\n",
      "loss: 0.532941  [ 6464/60000]\n",
      "loss: 0.349111  [12864/60000]\n",
      "loss: 0.580947  [19264/60000]\n",
      "loss: 0.521389  [25664/60000]\n",
      "loss: 0.516839  [32064/60000]\n",
      "loss: 0.517778  [38464/60000]\n",
      "loss: 0.664833  [44864/60000]\n",
      "loss: 0.617308  [51264/60000]\n",
      "loss: 0.478775  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.520593 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.404724  [   64/60000]\n",
      "loss: 0.528796  [ 6464/60000]\n",
      "loss: 0.345569  [12864/60000]\n",
      "loss: 0.576269  [19264/60000]\n",
      "loss: 0.516679  [25664/60000]\n",
      "loss: 0.513026  [32064/60000]\n",
      "loss: 0.514069  [38464/60000]\n",
      "loss: 0.665068  [44864/60000]\n",
      "loss: 0.615833  [51264/60000]\n",
      "loss: 0.473253  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.517513 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.399577  [   64/60000]\n",
      "loss: 0.524941  [ 6464/60000]\n",
      "loss: 0.342237  [12864/60000]\n",
      "loss: 0.571744  [19264/60000]\n",
      "loss: 0.512110  [25664/60000]\n",
      "loss: 0.509293  [32064/60000]\n",
      "loss: 0.510557  [38464/60000]\n",
      "loss: 0.665191  [44864/60000]\n",
      "loss: 0.614341  [51264/60000]\n",
      "loss: 0.467937  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.514597 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.394611  [   64/60000]\n",
      "loss: 0.521340  [ 6464/60000]\n",
      "loss: 0.339081  [12864/60000]\n",
      "loss: 0.567406  [19264/60000]\n",
      "loss: 0.507647  [25664/60000]\n",
      "loss: 0.505638  [32064/60000]\n",
      "loss: 0.507225  [38464/60000]\n",
      "loss: 0.665214  [44864/60000]\n",
      "loss: 0.612837  [51264/60000]\n",
      "loss: 0.462898  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.511832 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.389795  [   64/60000]\n",
      "loss: 0.518003  [ 6464/60000]\n",
      "loss: 0.336097  [12864/60000]\n",
      "loss: 0.563211  [19264/60000]\n",
      "loss: 0.503275  [25664/60000]\n",
      "loss: 0.502099  [32064/60000]\n",
      "loss: 0.504068  [38464/60000]\n",
      "loss: 0.665082  [44864/60000]\n",
      "loss: 0.611321  [51264/60000]\n",
      "loss: 0.458107  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.509208 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.385127  [   64/60000]\n",
      "loss: 0.514871  [ 6464/60000]\n",
      "loss: 0.333249  [12864/60000]\n",
      "loss: 0.559195  [19264/60000]\n",
      "loss: 0.499068  [25664/60000]\n",
      "loss: 0.498662  [32064/60000]\n",
      "loss: 0.501058  [38464/60000]\n",
      "loss: 0.664851  [44864/60000]\n",
      "loss: 0.609810  [51264/60000]\n",
      "loss: 0.453548  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.506712 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.380629  [   64/60000]\n",
      "loss: 0.511913  [ 6464/60000]\n",
      "loss: 0.330527  [12864/60000]\n",
      "loss: 0.555357  [19264/60000]\n",
      "loss: 0.494970  [25664/60000]\n",
      "loss: 0.495289  [32064/60000]\n",
      "loss: 0.498225  [38464/60000]\n",
      "loss: 0.664463  [44864/60000]\n",
      "loss: 0.608341  [51264/60000]\n",
      "loss: 0.449242  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.504332 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.376281  [   64/60000]\n",
      "loss: 0.509120  [ 6464/60000]\n",
      "loss: 0.327868  [12864/60000]\n",
      "loss: 0.551630  [19264/60000]\n",
      "loss: 0.491032  [25664/60000]\n",
      "loss: 0.492027  [32064/60000]\n",
      "loss: 0.495534  [38464/60000]\n",
      "loss: 0.663914  [44864/60000]\n",
      "loss: 0.606892  [51264/60000]\n",
      "loss: 0.445168  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.502064 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.372068  [   64/60000]\n",
      "loss: 0.506481  [ 6464/60000]\n",
      "loss: 0.325299  [12864/60000]\n",
      "loss: 0.548059  [19264/60000]\n",
      "loss: 0.487168  [25664/60000]\n",
      "loss: 0.488873  [32064/60000]\n",
      "loss: 0.492946  [38464/60000]\n",
      "loss: 0.663213  [44864/60000]\n",
      "loss: 0.605425  [51264/60000]\n",
      "loss: 0.441288  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.499895 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.367979  [   64/60000]\n",
      "loss: 0.503940  [ 6464/60000]\n",
      "loss: 0.322803  [12864/60000]\n",
      "loss: 0.544629  [19264/60000]\n",
      "loss: 0.483407  [25664/60000]\n",
      "loss: 0.485853  [32064/60000]\n",
      "loss: 0.490436  [38464/60000]\n",
      "loss: 0.662355  [44864/60000]\n",
      "loss: 0.603947  [51264/60000]\n",
      "loss: 0.437550  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.497817 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.363997  [   64/60000]\n",
      "loss: 0.501497  [ 6464/60000]\n",
      "loss: 0.320410  [12864/60000]\n",
      "loss: 0.541322  [19264/60000]\n",
      "loss: 0.479780  [25664/60000]\n",
      "loss: 0.482933  [32064/60000]\n",
      "loss: 0.488035  [38464/60000]\n",
      "loss: 0.661385  [44864/60000]\n",
      "loss: 0.602463  [51264/60000]\n",
      "loss: 0.434007  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.495824 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.360207  [   64/60000]\n",
      "loss: 0.499156  [ 6464/60000]\n",
      "loss: 0.318118  [12864/60000]\n",
      "loss: 0.538153  [19264/60000]\n",
      "loss: 0.476315  [25664/60000]\n",
      "loss: 0.480116  [32064/60000]\n",
      "loss: 0.485721  [38464/60000]\n",
      "loss: 0.660283  [44864/60000]\n",
      "loss: 0.601010  [51264/60000]\n",
      "loss: 0.430652  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.493915 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.356521  [   64/60000]\n",
      "loss: 0.496902  [ 6464/60000]\n",
      "loss: 0.315942  [12864/60000]\n",
      "loss: 0.535107  [19264/60000]\n",
      "loss: 0.472956  [25664/60000]\n",
      "loss: 0.477403  [32064/60000]\n",
      "loss: 0.483522  [38464/60000]\n",
      "loss: 0.659031  [44864/60000]\n",
      "loss: 0.599533  [51264/60000]\n",
      "loss: 0.427450  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.492074 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.352933  [   64/60000]\n",
      "loss: 0.494743  [ 6464/60000]\n",
      "loss: 0.313832  [12864/60000]\n",
      "loss: 0.532165  [19264/60000]\n",
      "loss: 0.469685  [25664/60000]\n",
      "loss: 0.474783  [32064/60000]\n",
      "loss: 0.481443  [38464/60000]\n",
      "loss: 0.657617  [44864/60000]\n",
      "loss: 0.598100  [51264/60000]\n",
      "loss: 0.424384  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.490302 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.349460  [   64/60000]\n",
      "loss: 0.492670  [ 6464/60000]\n",
      "loss: 0.311820  [12864/60000]\n",
      "loss: 0.529378  [19264/60000]\n",
      "loss: 0.466505  [25664/60000]\n",
      "loss: 0.472310  [32064/60000]\n",
      "loss: 0.479438  [38464/60000]\n",
      "loss: 0.656075  [44864/60000]\n",
      "loss: 0.596755  [51264/60000]\n",
      "loss: 0.421482  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.488593 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.346091  [   64/60000]\n",
      "loss: 0.490587  [ 6464/60000]\n",
      "loss: 0.309883  [12864/60000]\n",
      "loss: 0.526644  [19264/60000]\n",
      "loss: 0.463423  [25664/60000]\n",
      "loss: 0.469928  [32064/60000]\n",
      "loss: 0.477468  [38464/60000]\n",
      "loss: 0.654546  [44864/60000]\n",
      "loss: 0.595379  [51264/60000]\n",
      "loss: 0.418756  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.486941 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.342778  [   64/60000]\n",
      "loss: 0.488604  [ 6464/60000]\n",
      "loss: 0.308023  [12864/60000]\n",
      "loss: 0.524109  [19264/60000]\n",
      "loss: 0.460442  [25664/60000]\n",
      "loss: 0.467713  [32064/60000]\n",
      "loss: 0.475505  [38464/60000]\n",
      "loss: 0.652957  [44864/60000]\n",
      "loss: 0.593984  [51264/60000]\n",
      "loss: 0.416164  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.485336 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.339570  [   64/60000]\n",
      "loss: 0.486684  [ 6464/60000]\n",
      "loss: 0.306244  [12864/60000]\n",
      "loss: 0.521693  [19264/60000]\n",
      "loss: 0.457485  [25664/60000]\n",
      "loss: 0.465554  [32064/60000]\n",
      "loss: 0.473593  [38464/60000]\n",
      "loss: 0.651291  [44864/60000]\n",
      "loss: 0.592551  [51264/60000]\n",
      "loss: 0.413727  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.483783 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.336429  [   64/60000]\n",
      "loss: 0.484859  [ 6464/60000]\n",
      "loss: 0.304519  [12864/60000]\n",
      "loss: 0.519375  [19264/60000]\n",
      "loss: 0.454531  [25664/60000]\n",
      "loss: 0.463501  [32064/60000]\n",
      "loss: 0.471797  [38464/60000]\n",
      "loss: 0.649612  [44864/60000]\n",
      "loss: 0.591030  [51264/60000]\n",
      "loss: 0.411448  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.482273 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.333399  [   64/60000]\n",
      "loss: 0.483068  [ 6464/60000]\n",
      "loss: 0.302857  [12864/60000]\n",
      "loss: 0.517200  [19264/60000]\n",
      "loss: 0.451658  [25664/60000]\n",
      "loss: 0.461469  [32064/60000]\n",
      "loss: 0.470034  [38464/60000]\n",
      "loss: 0.647818  [44864/60000]\n",
      "loss: 0.589525  [51264/60000]\n",
      "loss: 0.409320  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.480806 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.330468  [   64/60000]\n",
      "loss: 0.481333  [ 6464/60000]\n",
      "loss: 0.301194  [12864/60000]\n",
      "loss: 0.515102  [19264/60000]\n",
      "loss: 0.448840  [25664/60000]\n",
      "loss: 0.459479  [32064/60000]\n",
      "loss: 0.468229  [38464/60000]\n",
      "loss: 0.645982  [44864/60000]\n",
      "loss: 0.587937  [51264/60000]\n",
      "loss: 0.407260  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.479380 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.327624  [   64/60000]\n",
      "loss: 0.479617  [ 6464/60000]\n",
      "loss: 0.299561  [12864/60000]\n",
      "loss: 0.513052  [19264/60000]\n",
      "loss: 0.446069  [25664/60000]\n",
      "loss: 0.457467  [32064/60000]\n",
      "loss: 0.466463  [38464/60000]\n",
      "loss: 0.644147  [44864/60000]\n",
      "loss: 0.586307  [51264/60000]\n",
      "loss: 0.405320  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.477981 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.324863  [   64/60000]\n",
      "loss: 0.477939  [ 6464/60000]\n",
      "loss: 0.297918  [12864/60000]\n",
      "loss: 0.511043  [19264/60000]\n",
      "loss: 0.443440  [25664/60000]\n",
      "loss: 0.455537  [32064/60000]\n",
      "loss: 0.464752  [38464/60000]\n",
      "loss: 0.642287  [44864/60000]\n",
      "loss: 0.584686  [51264/60000]\n",
      "loss: 0.403531  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.476616 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.322195  [   64/60000]\n",
      "loss: 0.476170  [ 6464/60000]\n",
      "loss: 0.296295  [12864/60000]\n",
      "loss: 0.509101  [19264/60000]\n",
      "loss: 0.440882  [25664/60000]\n",
      "loss: 0.453638  [32064/60000]\n",
      "loss: 0.463040  [38464/60000]\n",
      "loss: 0.640344  [44864/60000]\n",
      "loss: 0.583144  [51264/60000]\n",
      "loss: 0.401891  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.475281 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model to model.pth\n"
     ]
    }
   ],
   "source": [
    "model_path = \"model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Save model to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model = NeuralNetwork().to(device)\n",
    "eval_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
